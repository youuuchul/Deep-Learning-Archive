# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ê²½ë¡œ íƒìƒ‰ (ìµœì í™”ë¨)
# ---------------------------------------------------------
from src.data_loader import load_json_files, parse_data, split_data_leakage_proof, create_dataset_dict
import unicodedata

def find_data_dir():
    # 1. ê°€ì¥ í™•ì‹¤í•œ ê²½ë¡œ(Fallback Path)ë¶€í„° ë¨¼ì € í™•ì¸
    # (ì´ë¯¸ í†µí•© ì…‹ì—…ì—ì„œ codeit í´ë”ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ./data/... ê°€ ê°€ì¥ ìœ ë ¥)
    primary_target = Path("./data/ì‡¼í•‘ëª°/02. í™”ì¥í’ˆ")
    if primary_target.exists():
        logger.info(f"âœ… í‘œì¤€ ë°ì´í„° ê²½ë¡œ ë°œê²¬: {primary_target}")
        return primary_target

    # 2. ì—†ìœ¼ë©´ ìë™ íƒìƒ‰ ì‹œë„
    candidates = [Path("./data"), Path("../data")]
    for cand in candidates:
        if cand.exists():
            try:
                # ì‡¼í•‘ëª° í´ë” ì°¾ê¸°
                shopping_dir = next(cand.glob("*ì‡¼í•‘ëª°*"))
                target_categories = ["í™”ì¥í’ˆ", "ê°€ì „", "ITê¸°ê¸°", "íŒ¨ì…˜"]
                for category in target_categories:
                    for p in shopping_dir.glob("*"):
                        if category in unicodedata.normalize('NFC', p.name):
                            logger.info(f"ğŸ” ìë™ íƒìƒ‰ëœ ì¹´í…Œê³ ë¦¬: {p.name}")
                            return p
            except StopIteration:
                continue
    return None

# --- ì‹¤í–‰ë¶€ ---
DATA_DIR = find_data_dir()

if DATA_DIR is None:
    raise FileNotFoundError("ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ./data í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

logger.info(f"ğŸ“‚ ìµœì¢… ì‚¬ìš© ê²½ë¡œ: {DATA_DIR}")

# ìƒ˜í”Œë§ ì œí•œ (ë¡œì»¬ì¼ ë•Œë§Œ)
SAMPLE_LIMIT = 2000 if is_mac_local else None

try:
    logger.info("ğŸš€ ë°ì´í„° ë¡œë“œ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    
    # (1) íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    files = load_json_files(DATA_DIR)
    
    # (2) íŒŒì‹± (NoneType ì—ëŸ¬ ìˆ˜ì •ëœ ë²„ì „)
    df = parse_data(files, sample_limit=SAMPLE_LIMIT)
    
    # (3) ë¶„í• 
    train_df, test_df = split_data_leakage_proof(df)
    
    # (4) ë°ì´í„°ì…‹ ìƒì„±
    dataset = create_dataset_dict(train_df, test_df)

    print("\nâœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ!")
    print(dataset)

except Exception as e:
    logger.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    raise e