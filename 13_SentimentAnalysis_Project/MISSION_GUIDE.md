# 미션 가이드 및 결과 분석 리포트

본 문서는 단계별 체크리스트와 학습 결과에 대한 비교 분석 내용을 기록합니다.

## 1. 미션 수행 체크리스트
✅ [Step 0] 환경 설정 및 로컬 검증 (M1 Mac)
[ ] get_device()를 통한 MPS/CUDA 자동 감지 로직 구현
[ ] 로컬 환경에서의 데이터 로드 및 1개 배치(Batch) 테스트 통과

✅ [Step 1] 데이터 로드 및 전처리
[ ] JSON 파일 읽기 및 RawText, GeneralPolarity 추출
[ ] 라벨 맵핑 (-1 -> 0, 0 -> 1, 1 -> 2)
[ ] 학습(8):테스트(2) 데이터 분할 및 Dataset 객체 생성

✅ [Step 2] Full Fine-Tuning 모델 학습 (Colab)
[ ] 사전학습 모델 선정 근거 제시 및 로드
[ ] 전체 파라미터 학습 및 체크포인트 저장 로직 확인
[ ] 학습 로그(CSV) 생성 및 최종 모델 저장

✅ [Step 3] PEFT(LoRA) 모델 학습 (Colab)
[ ] 2026년 기준 최적 LoRA Config 설정 및 근거 주석 작성
[ ] 동일 조건 하에 PEFT 학습 진행 및 어댑터 저장

✅ [Step 4] 성능 평가 및 비교 분석
[ ] Accuracy/F1-score(Macro, Weighted) 측정
[ ] 모델 용량 및 학습 속도 데이터 취합

## 2. 최종 결과 비교 분석
비교 항목 | Full Fine-Tuning | PEFT (LoRA) | 차이 (Difference)
--- | --- | --- | ---
선택 분야 | - | - | -
Base Model | - | - | -
학습 시간 | 00분 00초 | 00분 00초 | 00% 증감
학습 파라미터 수 | 100% | 약 0.0% | -
저장 용량 | 000 MB | 00 MB | 약 1/n 수준
검증 정확도(Acc) | 00.0% | 00.0% | ±0.0%
F1-Score | 0.0000 | 0.0000 | ±0.0000

## 3. 분석 결론 및 인사이트
(이 섹션에는 학습 효율성, 성능 관점의 차이, 실무 적용 시 고려사항을 상세히 기술합니다.)