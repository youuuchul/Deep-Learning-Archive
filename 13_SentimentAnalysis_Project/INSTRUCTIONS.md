# 프로젝트 수행 가이드 (Anti-Gravity Instructions - 2026 Edition)

본 파일은 프로젝트의 코드 작성, 환경 대응 및 소통에 적용되는 최우선 규칙입니다.

## 1. 소통 및 보고 원칙
- 언어: 모든 소통은 한국어로 진행합니다.
- 사전 허락: 주요 단계(데이터 전처리 방식, 모델 아키텍처, 하이퍼파라미터 선정 등) 진행 전, 반드시 계획을 설명하고 사용자의 허락을 구한 뒤 실행합니다.
- 이모지 금지: 답변, 코드 주석, 마크다운 등 모든 출력물에서 이모지(Emoji)를 절대 사용하지 마십시오.

## 2. 하이브리드 환경 최적화 (Local to Cloud)
- 개발 워크플로우: 
    - 1단계 (로컬): Apple Silicon (M1) 환경에서 데이터 로드, EDA, 단일 배치(Single Batch) 실행 및 디버깅을 수행합니다.
    - 2단계 (코랩): 로컬 검증이 완료된 코드를 바탕으로 Google Colab (CUDA) 환경에서 본 학습과 가중치 저장을 수행하는 통합 노트북을 생성합니다.
- 장치 할당: `get_device()` 함수를 구현하여 MPS, CUDA, CPU 환경을 자동 감지하고 최적의 가속기를 할당하십시오.
- 로컬 세이프티: 로컬 환경(MPS)에서는 대규모 학습이 불가능함을 인지하고, 코드 무결성 체크를 위한 최소 단위 테스트 코드만 로컬에서 실행하도록 작성하십시오.

## 3. 코드 작성 및 전문성 가이드
- 하이퍼파라미터 근거: 모든 하이퍼파라미터(Learning Rate, Batch Size, LoRA Rank 등) 설정 시, 2026년 SOTA(State-of-the-Art) 논문 또는 신뢰할 수 있는 벤치마크 기준을 인용하여 주석으로 이유를 기술하십시오.
- 주석 상세화: 모델 레이어 및 주요 함수에는 설정 이유와 변경 시 고려사항을 상세히 기록하십시오.
- 로깅 시스템:
    - `print()`: 단순 정보 및 사용자 확인용 출력.
    - `logging`: 워크플로우 추적(시작/종료/에러)을 위한 체계적 기록.
- 최신성 유지: 2026년 기준 최신 버전의 transformers, peft, evaluate, accelerate 라이브러리를 사용하며 Deprecated된 함수는 절대 사용하지 마십시오.

## 4. 학습 및 저장 메커니즘
- 학습 연속성: 학습 중단 시 재개 가능한 체크포인트(Checkpoint) 저장 로직을 필수 포함하십시오.
- 분석용 데이터: 매 에폭/스텝마다 Loss 및 Evaluation Metric을 CSV 파일로 기록하여 사후 분석이 가능하게 하십시오.

## 5. 노트북 파일 디버깅
- 코드 무결성 우선: "노트북의 각 셀은 독립적으로 실행되더라도 변수가 이어지도록 작성해야 함"
- 스크립트-노트북 동기화: src/ 폴더에 있는 .py 파일의 함수 명칭이 노트북에서 호출하는 명칭과 정확히 일치하는지 항상 먼저 검토